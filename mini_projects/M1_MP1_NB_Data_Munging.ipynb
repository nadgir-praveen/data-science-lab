{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1OjFy4bqPCBbBi_AWvDcJLeL7v18lkPmQ","timestamp":1702123657431}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7rc1"}},"cells":[{"cell_type":"markdown","metadata":{"id":"aUUu9l_JfJ92"},"source":["# Advanced Certification Program in Computational Data Science\n","\n","##  A program by IISc and TalentSprint\n","\n","### Mini Project Notebook 1 : Data analytics\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SL3yrUc-XrLS"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"nljJR6CwfZN_"},"source":["\n","\n","At the end of the experiment, you will be able to :\n","\n","\n","* understand the requirements for a “clean” dataset, ready for use in statistical analysis\n","\n","* use Python libraries like Pandas, Numpy, and Matplotlib to perform the  data-preprocessing steps\n","\n","* obtain probability and statistics based insights from the data\n"]},{"cell_type":"markdown","metadata":{"id":"pMh1cTQ0Y0wZ"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"dlCSHY5_Y0wb"},"source":["The dataset chosen for this experiment is the **Play Store** dataset which is  publicly available and created with this [methodology](https://nycdatascience.com/blog/student-works/google-play-store-everything-that-you-need-to-know-about-the-android-market/)  \n","\n","This dataset consists of 10841 records. Each record is made up of 13 fields.\n","\n","**For example**, Each record consists of App, Category, Rating, Reviews, Size, Installs, Type, Price, Content Rating, Genres, Last Updated, Current Ver, and Android Ver."]},{"cell_type":"markdown","metadata":{"id":"KovpIBt2Ztv8"},"source":["## Problem Statement"]},{"cell_type":"markdown","metadata":{"id":"GYdLgvhhZtwA"},"source":["Before we can derive any meaningful insights from the Play Store data, it is essential to pre-process the data and make it suitable for further analysis. This pre-processing step forms a major part of data wrangling (or data munging) and ensures better quality data. It consists of the transformation and mapping of data from a \"raw\" data form into another format so that it is more valuable for a variety of downstream purposes such as analytics. Data analysts typically spend a sizeable amount of time in the process of data wrangling, compared to the actual analysis of the data."]},{"cell_type":"markdown","metadata":{"id":"SqM_j0MiZtv-"},"source":["After data munging is performed, several actionable insights can be derived from the Play Store apps data. Such insights could help to unlock the enormous potential to drive app-making businesses to success."]},{"cell_type":"code","metadata":{"id":"4Gi2zCP0ZtwB"},"source":["#@title Download the data\n","!wget -qq https://cdn.iisc.talentsprint.com/CDS/Datasets/googleplaystore.csv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"epVoy2b_Z05e"},"source":["#### Import required packages"]},{"cell_type":"code","metadata":{"id":"z1RX1oi_Z4Nu"},"source":["import numpy as np\n","import seaborn as sns\n","import pandas as pd\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YmOJDVdp9PYo"},"source":["#### Load the dataset"]},{"cell_type":"code","metadata":{"id":"6DrVCIg54LZp"},"source":["# YOUR CODE HERE\n","df = pd.read_csv(\"googleplaystore.csv\")\n","df.info()\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"li5KS0i3pQqq"},"source":["## Pre-processing"]},{"cell_type":"code","metadata":{"id":"rgCf41v3FHLw"},"source":["df = pd.read_csv(\"googleplaystore.csv\")\n","# YOUR CODE HERE\n","import math\n","\n","print(df.isnull().sum())\n","# Decide what values make sense for the columns where there are null\n","df = df.fillna({'Rating': 0.0}), 'Type': 'Free', 'Current Ver': 'Not Available', 'Android Ver': 'Not Available', 'Content Rating': 'Not rated'})\n","\n","print(df.isnull().sum())\n","\n","# converting reviews into numericals\n","df['Reviews'] = df['Reviews'].apply(\n","    lambda d: int(float(d.upper().replace('M', ''))*1000000) if 'M' in d.upper() else int(float(d.upper().replace('K', ''))*1000) if 'K' in d.upper() else int(d) )\n","\n","# removing duplicates\n","df_dupl = df[df.duplicated(subset=['App'])]\n","print('\\n Before: Duplicate entries for apps is : {} out of {}'.format(df_dupl.shape[0], df.shape[0]))\n","# there could be multiple entries for one app - which entry should be kept in that case?\n","# we can keep the one that has max values - assuming that might be latest\n","df = df.sort_values(['Last Updated', 'Rating', 'Reviews', 'Installs'], ascending=False).drop_duplicates(['App']).sort_index(ignore_index=True)\n","\n","# remove apps with non english characters\n","df_non_englsih = df[df['App'].apply(lambda d: not(str(d).isascii()))]\n","print('\\n Apps with Non English chars: {} out of {}'.format(df_non_englsih.shape[0], df.shape[0]))\n","df = df[df['App'].apply(lambda d: str(d).isascii())]\n","print('\\n Apps after removing non english : ', df.shape[0])\n","\n","df = df[df['Category'].apply(lambda d: str(d).isascii() and str(d).upper().isupper())]\n","print('\\n Apps after removing invalid categories : ', df.shape[0])\n","\n","# # getting average of the rating per category\n","# df_cat_rating = df.groupby('Category')['Rating'].aggregate('mean').drop_duplicates()\n","# df['Rating'] = df.apply(lambda r: df_cat_rating[r['Category']] if math.isnan(r['Rating']) else r['Rating'], axis=1)\n","# df = df[df['Rating'] <= 5.0]\n","# df = df['Rating'].fillna(0.0)\n","\n","print('\\n Final: Number of apps is {}'.format(df.shape[0]))\n","\n","# converting size to float, in MBs\n","translation = {'+': '', '+': '', 'k': '000', 'K': '000', 'M': '000000', 'm': '000000', ',':'', '.': ''}\n","transtable = ''.maketrans(translation)\n","df['Size'] = df['Size'].apply(lambda d: float(d.upper().translate(transtable))/1000000 if '0' <= d[0] <= '9' else 0)\n","# lambda d: float(d.upper().replace('M', ''))*1000000 if 'M' in d.upper() else float(d.upper().replace('K', ''))*1000 if 'K' in d.upper() else float(str(d).replace('+', '')) if '0' <= d[0] <= '9' else 0)\n","\n","# Converting price to float and assuming all in dollars\n","df['Price'] = df['Price'].apply(lambda d: float(d.replace('$', '')) if d[0] == '$' else 0)\n","# Converting installs into number, removing '+'\n","df['Installs'] = df['Installs'].apply(lambda d: int(str(d).replace('+', '').replace(',', '')) if '0' <= d[0] <= '9' else 0)\n","\n","# print(df['Installs'].unique())\n","# print(df['Size'].unique())\n","# print(df['Category'].unique())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VSrwuDKposoF"},"source":["### Task 1: Data Cleaning\n","\n","* Check whether there are any null values and figure out how you want to handle them?\n","  \n","    **Hint:** isnan(), dropna(), fillna()\n","* If there is any duplication of a record, how would you like to handle it?\n","\n","    Hint: [drop_duplicates](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html)\n","\n","* Are there any non-English apps? And how to filter them?\n","\n","* In the size column, multiply 1,000,000 with M in the cell and multiply by 1000 if we have K in the cell."]},{"cell_type":"markdown","metadata":{"id":"UrPzlHc4-zIR"},"source":["## Visualization"]},{"cell_type":"markdown","metadata":{"id":"qFgtC_jCpJL1"},"source":["### Task 2: Perform the  following tasks:"]},{"cell_type":"markdown","metadata":{"id":"5QQ2WUQX9XYy"},"source":["##### Exercise 1: Find the number of apps in various categories by using an appropriate plot."]},{"cell_type":"code","metadata":{"id":"zcRjzr9YRo72"},"source":["# YOUR CODE HERE\n","import seaborn.objects as so\n","\n","app_count = df['Category'].value_counts()\n","sns.set(style=\"darkgrid\")\n","sns.barplot(x=app_count.index, y=app_count.values, alpha=0.5, palette='turbo')\n","\n","# so.Plot(x=app_count.index, y=app_count.values).add(so.Bar(), so.Dodge(gap=0.4))\n","plt.title('Number of Apps in Various Categories')\n","plt.ylabel('Number of Apps', fontsize=12)\n","plt.xlabel('Category', fontsize=12)\n","plt.margins(0.02)\n","plt.tick_params(direction='out', length=6, width=2,\n","               grid_alpha=0.5, axis='x', labelsize='small', labelrotation=90)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uzzEnMv25vGn"},"source":["##### Exercise 2: Explore the distribution of free and paid apps across different categories\n","\n","**Hint:** Stacked Bar Graph, [link](https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/bar_stacked.html)"]},{"cell_type":"code","metadata":{"id":"UzxR7Gj4Rrbw"},"source":["# YOUR CODE HERE\n","\n","categories_count = df[df['Type'].isin(['Paid','Free'])]['Category'].value_counts()\n","app_free_count = df[df['Type']=='Free']['Category'].value_counts()\n","app_paid_count = df[df['Type']=='Paid']['Category'].value_counts()\n","\n","data = pd.DataFrame()\n","data['Category'] = categories_count.index\n","data = data.set_index('Category')\n","data.loc[categories_count.index, 'Free'] = app_free_count\n","data.loc[categories_count.index, 'Paid'] = app_paid_count\n","\n","p1 = plt.bar(data.index, data['Free'], width=0.8)\n","p2 = plt.bar(data.index, data['Paid'], width=0.8, bottom=data['Free'])\n","\n","plt.title('Number of Apps in Various Categories')\n","plt.ylabel('Number of Apps', fontsize=12)\n","plt.xlabel('Category', fontsize=12)\n","plt.margins(0.02)\n","plt.tick_params(direction='out', length=6, width=2,\n","               grid_alpha=0.5, axis='x', labelsize='small', labelrotation=90)\n","\n","plt.legend((p1[0], p2[0]), ('Free', 'Paid'))\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","plt.show()\n","\n","# data.plot(kind='bar', stacked=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OFNIQ4dj59Ep"},"source":["##### Exercise 3: Represent the distribution of app rating on a scale of 1-5 using an appropriate plot\n","\n","**Hint:** histogram / strip plot"]},{"cell_type":"code","metadata":{"id":"0ZDWxb_JRtBl"},"source":["# YOUR CODE HERE\n","# using the seaborn histogram\n","sns.histplot(data=df, x=\"Rating\", bins=20, binwidth=0.25, binrange=(0.0,5.0), stat='count')\n","\n","plt.title('App rating distribution')\n","plt.ylabel('Number of Apps', fontsize=12)\n","plt.xlabel('Rating', fontsize=12)\n","plt.margins(0.02)\n","plt.tick_params(direction='out', length=6, width=2,\n","               grid_alpha=0.5, axis='x', labelsize='small', labelrotation=90)\n","\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","plt.show()\n","\n","# Plotting a basic histogram sing matplotlib\n","# plt.hist(df['Rating'], color='skyblue', edgecolor='black', bins=24, range=(0,6.0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mWglBy3pDK3g"},"source":["\n","##### Exercise 4: Identify outliers of the rating column by plotting the boxplot category wise and handle them.\n","\n","**Hint:** Removing outliers using Z-score, quantile [link](https://kanoki.org/2020/04/23/how-to-remove-outliers-in-python/)"]},{"cell_type":"code","metadata":{"id":"ehVoOe9ARv0w"},"source":["# YOUR CODE HERE\n","from scipy import stats\n","\n","# df.boxplot('Rating', 'Category', rot=90, figsize=(15,8))\n","sns.boxplot(data=df, x=\"Category\", y=\"Rating\", width=0.5)\n","plt.ylim(0, 6)\n","plt.tick_params(direction='out', length=6, width=2,\n","               grid_alpha=0.5, axis='x', labelsize='small', labelrotation=90)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate the Z scores\n","for g,d in df.groupby('Category'):\n","    df.loc[df['Category']== g, 'z_score'] = stats.zscore(d['Rating'])\n","\n","# remove outliers where z score is > 3\n","df_processed = df[np.absolute(df['z_score']) < 3]\n","\n","sns.boxplot(data=df_processed, x=\"Category\", y=\"Rating\", width=0.5)\n","plt.ylim(0, 6)\n","plt.tick_params(direction='out', length=6, width=2,\n","               grid_alpha=0.5, axis='x', labelsize='small', labelrotation=90)\n","plt.rcParams[\"figure.figsize\"] = (12,6)"],"metadata":{"id":"qa5dXnzU2mcl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate the quartile scores\n","for g,d in df.groupby('Category'):\n","    q1 = d['Rating'].quantile(0.25)\n","    q3 = d['Rating'].quantile(0.75)\n","    df.loc[df['Category']==g, 'Q1'] = q1\n","    df.loc[df['Category']==g, 'Q3'] = q3\n","    df.loc[df['Category']==g, 'IQR'] = q3-q1\n","\n","filter = (df['Rating'] >= df['Q1'] - 1.5 * df['IQR']) & (df['Rating'] <= df['Q3'] + 1.5 * df['IQR'])\n","df_processed_1 = df.loc[filter]\n","\n","sns.boxplot(data=df_processed_1, x=\"Category\", y=\"Rating\", width=0.5, showfliers=False)\n","plt.ylim(0, 6)\n","plt.tick_params(direction='out', length=6, width=2,\n","               grid_alpha=0.5, axis='x', labelsize='small', labelrotation=90)\n","plt.rcParams[\"figure.figsize\"] = (12,6)"],"metadata":{"id":"NBKdrEKd7sqW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yiOWt855DsZ8"},"source":["##### Exercise 5: Plot the barplot of all the categories indicating no. of installs"]},{"cell_type":"code","metadata":{"id":"s3LW5CejRyBc"},"source":["# YOUR CODE HERE\n","import seaborn.objects as so\n","\n","install_total = df.groupby('Category')['Installs'].sum()\n","sns.set(style=\"darkgrid\")\n","sns.barplot(x=install_total.index, y=install_total.values, alpha=0.5, palette='turbo')\n","\n","# so.Plot(x=app_count.index, y=app_count.values).add(so.Bar(), so.Dodge(gap=0.4))\n","plt.title('Number of Installs in Various Categories')\n","plt.ylabel('Number of Installs', fontsize=12)\n","plt.xlabel('Category', fontsize=12)\n","plt.margins(0.02)\n","plt.tick_params(direction='out', length=6, width=2,\n","               grid_alpha=0.5, axis='x', labelsize='small', labelrotation=90)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nLNboJI1bDhL"},"source":["## Insights\n"]},{"cell_type":"markdown","metadata":{"id":"boBhK2SdGXlW"},"source":["### Task 3: Derive the below insights"]},{"cell_type":"markdown","metadata":{"id":"AtVLkGB_ANwf"},"source":["##### Exercise 1: Does the price correlate with the size of the app?\n","\n","  **Hint:** plot the scatterplot of `Size` and `Price`"]},{"cell_type":"code","metadata":{"id":"tDhPtmBCJC41"},"source":["# YOUR CODE HERE\n","sns.set(style='whitegrid')\n","# sns.scatterplot(x=df['Size'], y=df['Price'])\n","plt.scatter(df['Size'],df['Price'])\n","plt.title('Size Vs Price correlation')\n","plt.ylabel('Price in dollars', fontsize=12)\n","plt.xlabel('Size in MB', fontsize=12)\n","plt.margins(0.02)\n","plt.tick_params(direction='out', length=6, width=10,\n","               grid_alpha=0.5, axis='y', labelsize='small', labelrotation=0)\n","\n","plt.rcParams[\"figure.figsize\"] = (30,6)\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QqBPcp9rDcRh"},"source":["##### Exercise 2: Find the popular app categories based on rating and no. of installs\n","\n","**Hint:** [df.groupby.agg()](https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.core.groupby.DataFrameGroupBy.agg.html); Taking the average rating could be another approach\n","\n"]},{"cell_type":"code","metadata":{"id":"xWftl4eC2jNU"},"source":["# YOUR CODE HERE\n","df_top_cats = df.groupby('Category').agg({'Rating': 'mean', 'Installs': 'sum'}).sort_values(['Rating', 'Installs'], ascending=False)\n","print(\"The top 10 popular categories are: \\n\")\n","print(df_top_cats.head(10))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kksy2sD4CMKQ"},"source":["##### Exercise 3: How many apps are produced in each year category-wise ?\n","\n","  * Create a `Year` column by slicing the values of `Last Updated` column and find the Year with most no. of apps produced\n","\n","    **For example**, slice the year `2017` from `February 8, 2017`\n","\n","  * Find the categories which have a consistent rating in each year\n","\n","      **Hint:** `sns.countplot`"]},{"cell_type":"code","metadata":{"id":"3ZpnlYfHCO3P"},"source":["# YOUR CODE HERE\n","df['Year'] = df['Last Updated'].apply(lambda d: int(d.split()[2]))\n","sns.countplot(x ='Category', hue = \"Year\", data = df)\n","\n","plt.title('Number of Apps in Various Categories Year wise')\n","plt.ylabel('Number of Apps', fontsize=12)\n","plt.xlabel('Category', fontsize=12)\n","plt.margins(0.02)\n","plt.tick_params(direction='out', length=6, width=2,\n","               grid_alpha=0.5, axis='x', labelsize='small', labelrotation=90)\n","plt.rcParams[\"figure.figsize\"] = (20,6)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_high_rated = df[df['Rating']>=3.0]\n","# count plot on two categorical variable\n","sns.countplot(x ='Category', data=df_high_rated)\n","\n","plt.title('Consistent high rated Categories')\n","plt.ylabel('Number of Apps', fontsize=12)\n","plt.xlabel('Category', fontsize=12)\n","plt.margins(0.02)\n","plt.tick_params(direction='out', length=6, width=2,\n","               grid_alpha=0.5, axis='x', labelsize='small', labelrotation=90)\n","plt.rcParams[\"figure.figsize\"] = (12,6)"],"metadata":{"id":"QZlSqzpOnuVj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TnhRhfWadnGK"},"source":["##### Exercise 4: Identify the highest paid apps with a good rating"]},{"cell_type":"code","metadata":{"id":"9LmV1w_JdvRg"},"source":["# YOUR CODE HERE\n","df_highest_paid_good_rating = df.sort_values(['Price', 'Rating'], ascending=False, ignore_index=True)\n","df_highest_paid_good_rating = df_highest_paid_good_rating[df_highest_paid_good_rating['Rating']>=4]\n","\n","print(\"The top 10 highest paid apps with a good rating are: \\n\")\n","print(df_highest_paid_good_rating[['App', 'Price', 'Rating']].head(10))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NSCEb0GX5-d1"},"source":["##### Exercise 5: Are the top-rated apps genuine ? How about checking reviews count of top-rated apps ?"]},{"cell_type":"code","metadata":{"id":"n8kGpmMmx7HI"},"source":["# YOUR CODE HERE\n","df_top_rated = df.sort_values(['Rating', 'Reviews'], ascending=[False, True])\n","\n","print(\"The top rated apps with review counts are: \\n\")\n","print(df_top_rated[['App', 'Rating', 'Reviews']].head(50))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rXQfqIixzC4_"},"source":["##### Exercise 6: If the number of reviews of an app is very low, what could be the reason for its top-rating ?"]},{"cell_type":"code","metadata":{"id":"J_gj_f-UzGEF"},"source":["# YOUR CODE HERE\n","df_low_review = df.sort_values(['Reviews', 'Rating'], ascending=[True, False]).head(9000)\n","sns.scatterplot(x=df_low_review['Installs'],y=df_low_review['Rating'], hue=df['Reviews'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Exercise 7: What is the 95% confidence interval for the rating of apps in the Google Play Store?"],"metadata":{"id":"OGMPVx-oLVDM"}},{"cell_type":"code","metadata":{"id":"PCqAHD0OLyFj"},"source":["# YOUR CODE HERE\n","import scipy.stats as st\n","\n","print('mean = ', np.mean(df['Rating']))\n","print('se = ', st.sem(df['Rating'], nan_policy='omit'))\n","\n","ci_t_with_95 = st.t.interval(confidence=0.95, df=df.shape[0]-1, loc=np.mean(df['Rating']), scale=st.sem(df['Rating'], nan_policy='omit'))\n","\n","ci_norm_with_95 = st.norm.interval(confidence=0.95, loc=np.mean(df['Rating']), scale=st.sem(df['Rating'], nan_policy='omit'))\n","\n","print(\"CI (using normal distribution) = \", ci_norm_with_95)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Exercise 8: Test if there is a statistically significant difference in the ratings between free and paid apps using a t-test\n","\n","Steps:\n","\n","* Set the null hypothesis and alternate hypothesis\n","* Separate the ratings of free and paid apps.\n","* Perform t-test: Use an independent samples t-test.\n","* Interpret results based on the p-value, decide whether to reject or fail to reject the null hypothesis."],"metadata":{"id":"yTwkV1aqJ2VL"}},{"cell_type":"code","metadata":{"id":"cxxay7xvLA2U"},"source":["# YOUR CODE HERE\n","import scipy.stats as st\n","# H0 : there is no significant difference between free and paid apps when it comes to rating\n","# HA : there is a difference between free and paid apps on rating\n","\n","df_free_ratings = df[df['Type'] == 'Free']['Rating'].dropna()\n","df_paid_ratings = df[df['Type'] == 'Paid']['Rating'].dropna()\n","\n","print(\"Mean of ratings of free apps = \", round(df_free_ratings.mean(),4))\n","print(\"Mean of ratings of paid apps = \", round(df_paid_ratings.mean(), 4))\n","\n","ttest = st.ttest_ind(a = df_free_ratings, b = df_paid_ratings, equal_var= False, nan_policy='omit')\n","print('t-stat= ', round(ttest.statistic,4))\n","print('p value= ', round(ttest.pvalue,6))\n","# p value = 4e-06 is less than 0.05, so H0 is rejected.\n","# That is - here is a significant difference between paid and free apps when it comes to rating\n","\n","import statsmodels.api as sm\n","# Perform Two sample Z-test for Mean\n","two_sample_ztest = sm.stats.ztest(x1 = df_free_ratings,\n","                                  x2 = df_paid_ratings,\n","                                  value = 0,\n","                                  alternative = 'two-sided')    # Assume samples have equal variance\n","print(\"test-statistic (z-score): \", two_sample_ztest[0])\n","print(\"p-value: \", two_sample_ztest[1])"],"execution_count":null,"outputs":[]}]}